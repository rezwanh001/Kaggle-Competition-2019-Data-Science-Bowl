{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2019 Data Science Bowl_V-01.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rezwanh001/Kaggle-Competition-2019-Data-Science-Bowl/blob/master/2019_Data_Science_Bowl_V_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PolEHaKOY2h",
        "colab_type": "code",
        "outputId": "3b489dca-3540-46e0-8050-f6882e81d863",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGKW5Xt_O6dU",
        "colab_type": "text"
      },
      "source": [
        "## Mount the google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxlFNzStO3hC",
        "colab_type": "code",
        "outputId": "00350dc6-25b0-4e15-c0f9-ceebb6e934d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#root_path = 'drive/My Drive/your_project_folder/'  #change dir to your project folder"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fG9yQdyBNvm-",
        "colab_type": "text"
      },
      "source": [
        "## Install, Import dependencies and download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewoKznmuM5mY",
        "colab_type": "code",
        "outputId": "110a9422-91dc-4a96-f1db-8ae1eef279f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# to access kaggle datasets\n",
        "!pip install kaggle"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.6.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.9.11)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcngH__YPlYN",
        "colab_type": "code",
        "outputId": "11d3375e-38e0-4290-cacf-ddd4e37044ea",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "# Colab's file access feature\n",
        "from google.colab import files\n",
        "\n",
        "# retrieve upload file\n",
        "uploaded = files.upload()\n",
        "\n",
        "#print results\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "\n",
        "# Then move kaggle.jason into the folder where the API expects to to find it.\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a697dc5b-7719-4e90-8b23-024b6723617f\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-a697dc5b-7719-4e90-8b23-024b6723617f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "User uploaded file \"kaggle.json\" with length 65 bytes\n",
            "chmod: cannot access '/root/kaggle/kaggle.json': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gV4LiTmCP7AC",
        "colab_type": "code",
        "outputId": "2bac8310-1193-491d-97af-b71581fac179",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "# list of kaggle competitions\n",
        "!kaggle competitions list "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "ref                                            deadline             category            reward  teamCount  userHasEntered  \n",
            "---------------------------------------------  -------------------  ---------------  ---------  ---------  --------------  \n",
            "digit-recognizer                               2030-01-01 00:00:00  Getting Started  Knowledge       2466           False  \n",
            "titanic                                        2030-01-01 00:00:00  Getting Started  Knowledge      13476            True  \n",
            "house-prices-advanced-regression-techniques    2030-01-01 00:00:00  Getting Started  Knowledge       4917           False  \n",
            "imagenet-object-localization-challenge         2029-12-31 07:00:00  Research         Knowledge         56           False  \n",
            "tensorflow2-question-answering                 2020-01-22 23:59:00  Featured           $50,000        231           False  \n",
            "data-science-bowl-2019                         2020-01-22 23:59:00  Featured          $160,000        461            True  \n",
            "pku-autonomous-driving                         2020-01-21 23:59:00  Featured           $25,000        115            True  \n",
            "competitive-data-science-predict-future-sales  2019-12-31 23:59:00  Playground           Kudos       4675           False  \n",
            "ashrae-energy-prediction                       2019-12-19 23:59:00  Featured           $25,000       1465           False  \n",
            "Kannada-MNIST                                  2019-12-17 23:59:00  Playground       Knowledge        593           False  \n",
            "bigquery-geotab-intersection-congestion        2019-12-12 23:59:00  Playground           Kudos        331           False  \n",
            "cat-in-the-dat                                 2019-12-09 23:59:00  Playground            Swag        977           False  \n",
            "nfl-big-data-bowl-2020                         2019-11-27 23:59:00  Featured           $75,000       1194            True  \n",
            "understanding_cloud_organization               2019-11-18 23:59:00  Research           $10,000       1213           False  \n",
            "3d-object-detection-for-autonomous-vehicles    2019-11-12 23:59:00  Featured           $25,000        482           False  \n",
            "rsna-intracranial-hemorrhage-detection         2019-11-11 23:59:00  Featured           $25,000       1293           False  \n",
            "severstal-steel-defect-detection               2019-10-24 23:59:00  Featured          $120,000       2434           False  \n",
            "kuzushiji-recognition                          2019-10-14 23:59:00  Playground         $15,000        293           False  \n",
            "youtube8m-2019                                 2019-10-11 23:59:00  Research           $25,000        283           False  \n",
            "ieee-fraud-detection                           2019-10-03 23:59:00  Research           $20,000       6381            True  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0CzX_AbQls4",
        "colab_type": "code",
        "outputId": "1e91aaf6-9f5b-4898-d056-71d161eacab1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "## download the dataset of data-science-bowl-2019\n",
        "!kaggle competitions download -c data-science-bowl-2019 -p /content/drive/My\\ Drive/Kaggle\\ Competition:\\ 2019\\ Data\\ Science\\ Bowl/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading specs.csv to /content/drive/My Drive/Kaggle Competition: 2019 Data Science Bowl\n",
            "  0% 0.00/399k [00:00<?, ?B/s]\n",
            "100% 399k/399k [00:00<00:00, 27.1MB/s]\n",
            "Downloading sample_submission.csv to /content/drive/My Drive/Kaggle Competition: 2019 Data Science Bowl\n",
            "  0% 0.00/10.8k [00:00<?, ?B/s]\n",
            "100% 10.8k/10.8k [00:00<00:00, 174kB/s]\n",
            "Downloading train_labels.csv.zip to /content/drive/My Drive/Kaggle Competition: 2019 Data Science Bowl\n",
            "  0% 0.00/262k [00:00<?, ?B/s]\n",
            "100% 262k/262k [00:00<00:00, 34.5MB/s]\n",
            "Downloading test.csv.zip to /content/drive/My Drive/Kaggle Competition: 2019 Data Science Bowl\n",
            " 96% 39.0M/40.8M [00:01<00:00, 15.0MB/s]\n",
            "100% 40.8M/40.8M [00:01<00:00, 30.2MB/s]\n",
            "Downloading train.csv.zip to /content/drive/My Drive/Kaggle Competition: 2019 Data Science Bowl\n",
            " 99% 392M/397M [00:09<00:00, 51.6MB/s]\n",
            "100% 397M/397M [00:09<00:00, 43.9MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrqUKkHTV6ci",
        "colab_type": "text"
      },
      "source": [
        "## Extract the files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoWDmbdCR6bn",
        "colab_type": "code",
        "outputId": "94975ca1-99c5-4d63-960e-630f08de4fef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/Kaggle Competition: 2019 Data Science Bowl/')  #change dir\n",
        "!mkdir train  #create a directory named train/\n",
        "!mkdir test  #create a directory named test/\n",
        "!unzip -q train.csv.zip -d train/  #unzip data in train/\n",
        "!unzip -q test.csv.zip -d test/  #unzip data in test/\n",
        "# !unzip sample_submission.csv.zip\n",
        "!unzip train_labels.csv.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  train_labels.csv.zip\n",
            "  inflating: train_labels.csv        \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lS4FTJfxWbNR",
        "colab_type": "code",
        "outputId": "ed00f4eb-4e77-4ba8-a90d-3953735f2a06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# !unzip -q train.csv.zip -d train/  #unzip data in train/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "replace train/train.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PM_wOSJmXMiw",
        "colab_type": "code",
        "outputId": "16789b6d-b63b-44c8-80c8-84beb4440b13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls /content/drive/My\\ Drive/Kaggle\\ Competition:\\ 2019\\ Data\\ Science\\ Bowl/train/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tRlbzBmZnVK",
        "colab_type": "text"
      },
      "source": [
        "## Step-1: Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xKrYdzgXbHI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#===========================================================\n",
        "# Library\n",
        "#===========================================================\n",
        "import os\n",
        "import gc\n",
        "from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n",
        "from contextlib import contextmanager\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy as sp\n",
        "import random\n",
        "\n",
        "from functools import partial\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold, GroupKFold\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "import torch\n",
        "\n",
        "import lightgbm as lgb\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EY3_W7glewMx",
        "colab_type": "text"
      },
      "source": [
        "## Step-2: Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpvROW--aTYr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_logger(filename='log'):\n",
        "    logger = getLogger(__name__)\n",
        "    logger.setLevel(INFO)\n",
        "    handler1 = StreamHandler()\n",
        "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
        "    handler2 = FileHandler(filename=f\"{filename}.log\")\n",
        "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
        "    logger.addHandler(handler1)\n",
        "    logger.addHandler(handler2)\n",
        "    return logger\n",
        "\n",
        "logger = get_logger()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4uZqETde9GV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@contextmanager\n",
        "def timer(name):\n",
        "    t0 = time.time()\n",
        "    yield\n",
        "    logger.info(f'[{name}] done in {time.time() - t0:.0f} s')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mr16SHyyfCQ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seed_everything(seed=777):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7EsA9nnfM06",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_df(path, df_name, debug=False):\n",
        "    if path.split('.')[-1]=='csv':\n",
        "        df = pd.read_csv(path)\n",
        "        if debug:\n",
        "            df = pd.read_csv(path, nrows=1000)\n",
        "    elif path.split('.')[-1]=='pkl':\n",
        "        df = pd.read_pickle(path)\n",
        "    if logger==None:\n",
        "        print(f\"{df_name} shape / {df.shape} \")\n",
        "    else:\n",
        "        logger.info(f\"{df_name} shape / {df.shape} \")\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UImGvmBfVhi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_folds(_df, _id, target, fold, group=None, save_path='folds.csv'):\n",
        "    df = _df.copy()\n",
        "    if group==None:\n",
        "        for n, (train_index, val_index) in enumerate(fold.split(df, df[target])):\n",
        "            df.loc[val_index, 'fold'] = int(n)\n",
        "    else:\n",
        "        le = preprocessing.LabelEncoder()\n",
        "        groups = le.fit_transform(df[group].values)\n",
        "        for n, (train_index, val_index) in enumerate(fold.split(df, df[target], groups)):\n",
        "            df.loc[val_index, 'fold'] = int(n)\n",
        "    df['fold'] = df['fold'].astype(int)\n",
        "    df[[_id, target, 'fold']].to_csv(save_path, index=None)\n",
        "    return df[[_id, target, 'fold']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRf-J6gPffLs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def quadratic_weighted_kappa(y_hat, y):\n",
        "    return cohen_kappa_score(y_hat, y, weights='quadratic')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8z7S8dFmfkmV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class OptimizedRounder():\n",
        "    def __init__(self):\n",
        "        self.coef_ = 0\n",
        "\n",
        "    def _kappa_loss(self, coef, X, y):\n",
        "        X_p = np.copy(X)\n",
        "        for i, pred in enumerate(X_p):\n",
        "            if pred < coef[0]:\n",
        "                X_p[i] = 0\n",
        "            elif pred >= coef[0] and pred < coef[1]:\n",
        "                X_p[i] = 1\n",
        "            elif pred >= coef[1] and pred < coef[2]:\n",
        "                X_p[i] = 2\n",
        "            else:\n",
        "                X_p[i] = 3\n",
        "\n",
        "        ll = quadratic_weighted_kappa(y, X_p)\n",
        "        return -ll\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        loss_partial = partial(self._kappa_loss, X=X, y=y)\n",
        "        initial_coef = [0.5, 1.5, 2.5]\n",
        "        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n",
        "\n",
        "    def predict(self, X, coef):\n",
        "        X_p = np.copy(X)\n",
        "        for i, pred in enumerate(X_p):\n",
        "            if pred < coef[0]:\n",
        "                X_p[i] = 0\n",
        "            elif pred >= coef[0] and pred < coef[1]:\n",
        "                X_p[i] = 1\n",
        "            elif pred >= coef[1] and pred < coef[2]:\n",
        "                X_p[i] = 2\n",
        "            else:\n",
        "                X_p[i] = 3\n",
        "        return X_p\n",
        "\n",
        "    def coefficients(self):\n",
        "        return self.coef_['x']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZRL74VQfz6Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reduce_mem_usage(df, verbose=True):\n",
        "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "    start_mem = df.memory_usage().sum() / 1024**2    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtypes\n",
        "        if col_type in numerics:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)    \n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    if verbose: \n",
        "        logger.info('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
        "    return df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsySfYFGf8h2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#===========================================================\n",
        "# Config\n",
        "#===========================================================\n",
        "PARENT_DICT = '/content/drive/My Drive/Kaggle Competition: 2019 Data Science Bowl/'\n",
        "df_path_dict = {'train': PARENT_DICT + 'train/'+'train.csv',\n",
        "                'test': PARENT_DICT + 'test/' +'test.csv',\n",
        "                'train_labels': PARENT_DICT+'train_labels.csv', \n",
        "                'specs': PARENT_DICT+'specs.csv', \n",
        "                'sample_submission': PARENT_DICT+'sample_submission.csv'}\n",
        "                \n",
        "OUTPUT_DICT = '/content/drive/My Drive/Kaggle Competition: 2019 Data Science Bowl/Outputs/'\n",
        "\n",
        "ID = 'installation_id'\n",
        "TARGET = 'accuracy_group'\n",
        "SEED = 42\n",
        "seed_everything(seed=SEED)\n",
        "\n",
        "N_FOLD = 5\n",
        "Fold = GroupKFold(n_splits=N_FOLD)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06AW_BMehwq5",
        "colab_type": "text"
      },
      "source": [
        "## Step-3: Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9C7aq7udhqrm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#===========================================================\n",
        "# Feature Engineering\n",
        "# credits: \n",
        "# https://www.kaggle.com/ragnar123/simple-exploratory-data-analysis-and-model\n",
        "# https://www.kaggle.com/gpreda/data-science-bowl-fast-compact-solution\n",
        "#===========================================================\n",
        "def extract_time_features(df):\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "    df['date'] = df['timestamp'].dt.date\n",
        "    df['month'] = df['timestamp'].dt.month\n",
        "    df['hour'] = df['timestamp'].dt.hour\n",
        "    df['dayofweek'] = df['timestamp'].dt.dayofweek  \n",
        "    return df\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bft44D-Ph4vV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_object_columns(df, columns):\n",
        "    df = df.groupby(['installation_id', columns])['event_id'].count().reset_index()\n",
        "    df = df.pivot_table(index = 'installation_id', columns = [columns], values = 'event_id')\n",
        "    df.columns = list(df.columns)\n",
        "    df.fillna(0, inplace = True)\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWwqRtEah7h-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_numeric_columns(df, column):\n",
        "    df = df.groupby('installation_id').agg({f'{column}': ['mean', 'sum', 'min', 'max', 'std']})\n",
        "    df.fillna(0, inplace = True)\n",
        "    df.columns = [f'{column}_mean', f'{column}_sum', f'{column}_min', f'{column}_max', f'{column}_std']\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHoS3OdRh-nq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_numeric_columns_add(df, agg_column, column):\n",
        "    df = df.groupby(['installation_id', agg_column]).agg({f'{column}': ['mean', 'sum', 'min', 'max', 'std']}).reset_index()\n",
        "    df = df.pivot_table(index = 'installation_id', columns = [agg_column], values = [col for col in df.columns if col not in ['installation_id', 'type']])\n",
        "    df.fillna(0, inplace = True)\n",
        "    df.columns = list(df.columns)\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVBxfQzTiBnv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def perform_features_engineering(train_df, test_df, train_labels_df):\n",
        "    print(f'Perform features engineering')\n",
        "    numerical_columns = ['game_time']\n",
        "    categorical_columns = ['type', 'world']\n",
        "\n",
        "    comp_train_df = pd.DataFrame({'installation_id': train_df['installation_id'].unique()})\n",
        "    comp_train_df.set_index('installation_id', inplace = True)\n",
        "    comp_test_df = pd.DataFrame({'installation_id': test_df['installation_id'].unique()})\n",
        "    comp_test_df.set_index('installation_id', inplace = True)\n",
        "\n",
        "    test_df = extract_time_features(test_df)\n",
        "    train_df = extract_time_features(train_df)\n",
        "\n",
        "    for i in numerical_columns:\n",
        "        comp_train_df = comp_train_df.merge(get_numeric_columns(train_df, i), left_index = True, right_index = True)\n",
        "        comp_test_df = comp_test_df.merge(get_numeric_columns(test_df, i), left_index = True, right_index = True)\n",
        "    \n",
        "    for i in categorical_columns:\n",
        "        comp_train_df = comp_train_df.merge(get_object_columns(train_df, i), left_index = True, right_index = True)\n",
        "        comp_test_df = comp_test_df.merge(get_object_columns(test_df, i), left_index = True, right_index = True)\n",
        "    \n",
        "    for i in categorical_columns:\n",
        "        for j in numerical_columns:\n",
        "            comp_train_df = comp_train_df.merge(get_numeric_columns_add(train_df, i, j), left_index = True, right_index = True)\n",
        "            comp_test_df = comp_test_df.merge(get_numeric_columns_add(test_df, i, j), left_index = True, right_index = True)\n",
        "    \n",
        "    \n",
        "    comp_train_df.reset_index(inplace = True)\n",
        "    comp_test_df.reset_index(inplace = True)\n",
        "    \n",
        "    print('Our training set have {} rows and {} columns'.format(comp_train_df.shape[0], comp_train_df.shape[1]))\n",
        "\n",
        "    # get the mode of the title\n",
        "    labels_map = dict(train_labels_df.groupby('title')['accuracy_group'].agg(lambda x:x.value_counts().index[0]))\n",
        "    # merge target\n",
        "    labels = train_labels_df[['installation_id', 'title', 'accuracy_group']]\n",
        "    # replace title with the mode\n",
        "    labels['title'] = labels['title'].map(labels_map)\n",
        "    # get title from the test set\n",
        "    comp_test_df['title'] = test_df.groupby('installation_id').last()['title'].map(labels_map).reset_index(drop = True)\n",
        "    # join train with labels\n",
        "    comp_train_df = labels.merge(comp_train_df, on = 'installation_id', how = 'left')\n",
        "    print('We have {} training rows'.format(comp_train_df.shape[0]))\n",
        "    \n",
        "    return comp_train_df, comp_test_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QujbTBWLicGa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#===========================================================\n",
        "# model\n",
        "#===========================================================\n",
        "def run_single_lightgbm(param, train_df, test_df, folds, features, target, fold_num=0, categorical=[]):\n",
        "    \n",
        "    trn_idx = folds[folds.fold != fold_num].index\n",
        "    val_idx = folds[folds.fold == fold_num].index\n",
        "    logger.info(f'len(trn_idx) : {len(trn_idx)}')\n",
        "    logger.info(f'len(val_idx) : {len(val_idx)}')\n",
        "    \n",
        "    if categorical == []:\n",
        "        trn_data = lgb.Dataset(train_df.iloc[trn_idx][features],\n",
        "                               label=target.iloc[trn_idx])\n",
        "        val_data = lgb.Dataset(train_df.iloc[val_idx][features],\n",
        "                               label=target.iloc[val_idx])\n",
        "    else:\n",
        "        trn_data = lgb.Dataset(train_df.iloc[trn_idx][features],\n",
        "                               label=target.iloc[trn_idx],\n",
        "                               categorical_feature=categorical)\n",
        "        val_data = lgb.Dataset(train_df.iloc[val_idx][features],\n",
        "                               label=target.iloc[val_idx],\n",
        "                               categorical_feature=categorical)\n",
        "\n",
        "    oof = np.zeros(len(train_df))\n",
        "    predictions = np.zeros(len(test_df))\n",
        "\n",
        "    num_round = 10000\n",
        "\n",
        "    clf = lgb.train(param,\n",
        "                    trn_data,\n",
        "                    num_round,\n",
        "                    valid_sets=[trn_data, val_data],\n",
        "                    verbose_eval=1000,\n",
        "                    early_stopping_rounds=100)\n",
        "\n",
        "    oof[val_idx] = clf.predict(train_df.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
        "\n",
        "    fold_importance_df = pd.DataFrame()\n",
        "    fold_importance_df[\"Feature\"] = features\n",
        "    fold_importance_df[\"importance\"] = clf.feature_importance(importance_type='gain')\n",
        "    fold_importance_df[\"fold\"] = fold_num\n",
        "\n",
        "    predictions += clf.predict(test_df[features], num_iteration=clf.best_iteration)\n",
        "    \n",
        "    # RMSE\n",
        "    logger.info(\"fold{} RMSE score: {:<8.5f}\".format(fold_num, np.sqrt(mean_squared_error(target[val_idx], oof[val_idx]))))\n",
        "    \n",
        "    # QWK\n",
        "    optR = OptimizedRounder()\n",
        "    optR.fit(oof[val_idx], target[val_idx])\n",
        "    coefficients = optR.coefficients()\n",
        "    #coefficients = [0.5, 1.5, 2.5]\n",
        "    logger.info(f\"coefficients: {coefficients}\")\n",
        "    qwk_oof = optR.predict(oof[val_idx], coefficients)\n",
        "    logger.info(\"fold{} QWK score: {:<8.5f}\".format(fold_num, quadratic_weighted_kappa(qwk_oof, target[val_idx])))\n",
        "    \n",
        "    return oof, predictions, fold_importance_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc2O02LFilsL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_kfold_lightgbm(param, train, test, folds, features, target, n_fold=5, categorical=[]):\n",
        "    \n",
        "    logger.info(f\"================================= {n_fold}fold lightgbm =================================\")\n",
        "    \n",
        "    oof = np.zeros(len(train))\n",
        "    predictions = np.zeros(len(test))\n",
        "    feature_importance_df = pd.DataFrame()\n",
        "\n",
        "    for fold_ in range(n_fold):\n",
        "        print(\"Fold {}\".format(fold_))\n",
        "        _oof, _predictions, fold_importance_df = run_single_lightgbm(param,\n",
        "                                                                     train,\n",
        "                                                                     test,\n",
        "                                                                     folds,\n",
        "                                                                     features,\n",
        "                                                                     target,\n",
        "                                                                     fold_num=fold_,\n",
        "                                                                     categorical=categorical)\n",
        "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
        "        oof += _oof\n",
        "        predictions += _predictions / n_fold\n",
        "\n",
        "    # RMSE\n",
        "    logger.info(\"CV RMSE score: {:<8.5f}\".format(np.sqrt(mean_squared_error(target, oof))))\n",
        "    \n",
        "    # QWK\n",
        "    optR = OptimizedRounder()\n",
        "    optR.fit(oof, target)\n",
        "    coefficients = optR.coefficients()\n",
        "    #coefficients = [0.5, 1.5, 2.5]\n",
        "    logger.info(f\"coefficients: {coefficients}\")\n",
        "    qwk_oof = optR.predict(oof, coefficients)\n",
        "    logger.info(\"CV QWK score: {:<8.5f}\"\n",
        "                .format(quadratic_weighted_kappa(qwk_oof, target)))\n",
        "    qwk_predictions = optR.predict(predictions, coefficients)\n",
        "    \n",
        "    submission = pd.DataFrame({f\"{ID}\": test[ID].values, f\"{TARGET}\": qwk_predictions})\n",
        "    submission[TARGET] = submission[TARGET].astype(int)\n",
        "    submission.to_csv(OUTPUT_DICT+'submission.csv', index=False)\n",
        "    feature_importance_df.to_csv(OUTPUT_DICT+'feature_importance_df_lightgbm.csv', index=False)\n",
        "\n",
        "    logger.info(f\"=========================================================================================\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYR8P5QrirZY",
        "colab_type": "code",
        "outputId": "a8671a44-0db9-412f-f7ea-2cb70182e399",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#===========================================================\n",
        "# main\n",
        "#===========================================================\n",
        "def main():\n",
        "    \n",
        "    DEBUG = False\n",
        "    \n",
        "    with timer('Data Loading'):\n",
        "        train = load_df(path=df_path_dict['train'], df_name='train', debug=DEBUG)\n",
        "        train = reduce_mem_usage(train)\n",
        "        train_labels = load_df(path=df_path_dict['train_labels'], df_name='train_labels', debug=DEBUG)\n",
        "        test = load_df(path=df_path_dict['test'], df_name='test', debug=DEBUG)\n",
        "        test = reduce_mem_usage(test)\n",
        "        #specs = load_df(path=df_path_dict['specs'], df_name='specs')\n",
        "        sample_submission = load_df(path=df_path_dict['sample_submission'], df_name='sample_submission')\n",
        "    \n",
        "    with timer('Creating features'):\n",
        "        train_df, test_df = perform_features_engineering(train, test, train_labels)\n",
        "        del train, test, train_labels; gc.collect()\n",
        "        train_df = reduce_mem_usage(train_df)\n",
        "        test_df = reduce_mem_usage(test_df)\n",
        "        logger.info(f'train_df shape : {train_df.shape}')\n",
        "        train_df.to_csv('train.csv', index=False)\n",
        "        logger.info(f'test_df shape : {test_df.shape}')\n",
        "        test_df.to_csv('test.csv', index=False)\n",
        "        \n",
        "    with timer('Run lightgbm'):\n",
        "        lgb_param = {\n",
        "                'objective': 'regression',\n",
        "                'metric': 'rmse',\n",
        "                'boosting_type': 'gbdt',\n",
        "                'learning_rate': 0.01,\n",
        "                'data_random_seed': SEED,\n",
        "                'max_depth': -1,\n",
        "                'subsample': 0.8,\n",
        "                'colsample_bytree': 0.7,\n",
        "                'reg_alpha': 0.1,\n",
        "                'reg_lambda': 0.1,\n",
        "                'min_data_in_leaf': 100,\n",
        "            }\n",
        "        logger.info(f\"lgb_param : {lgb_param}\")\n",
        "        \n",
        "        target = train_df[TARGET]\n",
        "        folds = make_folds(train_df, ID, TARGET, Fold, group='installation_id')\n",
        "        test_df = pd.concat([sample_submission.set_index('installation_id').drop(columns=['accuracy_group']), \n",
        "                             test_df.set_index('installation_id')], axis=1).reset_index()\n",
        "        \n",
        "        num_features = [c for c in test_df.columns if test_df.dtypes[c] != 'object']\n",
        "        cat_features = ['title']\n",
        "        features = num_features + cat_features\n",
        "        drop_features = [ID, TARGET, 'accuracy']\n",
        "        features = [c for c in features if c not in drop_features]\n",
        "        logger.info(features)\n",
        "        \n",
        "        if cat_features:\n",
        "            for c in cat_features:\n",
        "                le = LabelEncoder()\n",
        "                le.fit(train_df[c])\n",
        "                train_df[c] = le.transform(train_df[c])\n",
        "                test_df[c] = le.transform(test_df[c])\n",
        "        \n",
        "        run_kfold_lightgbm(lgb_param, train_df, test_df, folds, features, target, n_fold=N_FOLD, categorical=cat_features)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train shape / (11341042, 11) \n",
            "Mem. usage decreased to 778.73 Mb (18.2% reduction)\n",
            "train_labels shape / (17690, 7) \n",
            "test shape / (1156414, 11) \n",
            "Mem. usage decreased to 79.40 Mb (18.2% reduction)\n",
            "sample_submission shape / (1000, 2) \n",
            "[Data Loading] done in 65 s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Perform features engineering\n",
            "Our training set have 17000 rows and 54 columns\n",
            "We have 17690 training rows\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Mem. usage decreased to  3.02 Mb (60.0% reduction)\n",
            "Mem. usage decreased to  0.16 Mb (60.6% reduction)\n",
            "train_df shape : (17690, 56)\n",
            "test_df shape : (1000, 55)\n",
            "[Creating features] done in 35 s\n",
            "lgb_param : {'objective': 'regression', 'metric': 'rmse', 'boosting_type': 'gbdt', 'learning_rate': 0.01, 'data_random_seed': 42, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1, 'min_data_in_leaf': 100}\n",
            "['game_time_mean', 'game_time_sum', 'game_time_min', 'game_time_max', 'game_time_std', 'Activity', 'Assessment', 'Clip', 'Game', 'CRYSTALCAVES', 'MAGMAPEAK', 'NONE', 'TREETOPCITY', ('game_time', 'max', 'Activity'), ('game_time', 'max', 'Assessment'), ('game_time', 'max', 'Clip'), ('game_time', 'max', 'Game'), ('game_time', 'mean', 'Activity'), ('game_time', 'mean', 'Assessment'), ('game_time', 'mean', 'Clip'), ('game_time', 'mean', 'Game'), ('game_time', 'min', 'Activity'), ('game_time', 'min', 'Assessment'), ('game_time', 'min', 'Clip'), ('game_time', 'min', 'Game'), ('game_time', 'std', 'Activity'), ('game_time', 'std', 'Assessment'), ('game_time', 'std', 'Clip'), ('game_time', 'std', 'Game'), ('game_time', 'sum', 'Activity'), ('game_time', 'sum', 'Assessment'), ('game_time', 'sum', 'Clip'), ('game_time', 'sum', 'Game'), ('game_time', 'max', 'CRYSTALCAVES'), ('game_time', 'max', 'MAGMAPEAK'), ('game_time', 'max', 'NONE'), ('game_time', 'max', 'TREETOPCITY'), ('game_time', 'mean', 'CRYSTALCAVES'), ('game_time', 'mean', 'MAGMAPEAK'), ('game_time', 'mean', 'NONE'), ('game_time', 'mean', 'TREETOPCITY'), ('game_time', 'min', 'CRYSTALCAVES'), ('game_time', 'min', 'MAGMAPEAK'), ('game_time', 'min', 'NONE'), ('game_time', 'min', 'TREETOPCITY'), ('game_time', 'std', 'CRYSTALCAVES'), ('game_time', 'std', 'MAGMAPEAK'), ('game_time', 'std', 'NONE'), ('game_time', 'std', 'TREETOPCITY'), ('game_time', 'sum', 'CRYSTALCAVES'), ('game_time', 'sum', 'MAGMAPEAK'), ('game_time', 'sum', 'NONE'), ('game_time', 'sum', 'TREETOPCITY'), 'title', 'title']\n",
            "================================= 5fold lightgbm =================================\n",
            "len(trn_idx) : 14152\n",
            "len(val_idx) : 3538\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fold 0\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[621]\ttraining's rmse: 0.944157\tvalid_1's rmse: 1.05374\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fold0 RMSE score: 1.05374 \n",
            "coefficients: [0.5825708  1.53098592 2.0599877 ]\n",
            "fold0 QWK score: 0.49476 \n",
            "len(trn_idx) : 14152\n",
            "len(val_idx) : 3538\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fold 1\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[395]\ttraining's rmse: 0.975385\tvalid_1's rmse: 1.09572\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fold1 RMSE score: 1.09572 \n",
            "coefficients: [0.52854356 1.61999428 2.16698323]\n",
            "fold1 QWK score: 0.41870 \n",
            "len(trn_idx) : 14152\n",
            "len(val_idx) : 3538\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fold 2\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[377]\ttraining's rmse: 0.979613\tvalid_1's rmse: 1.06381\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fold2 RMSE score: 1.06381 \n",
            "coefficients: [0.5521229  1.61860066 2.08690247]\n",
            "fold2 QWK score: 0.45718 \n",
            "len(trn_idx) : 14152\n",
            "len(val_idx) : 3538\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fold 3\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[475]\ttraining's rmse: 0.955871\tvalid_1's rmse: 1.11107\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fold3 RMSE score: 1.11107 \n",
            "coefficients: [0.51039996 1.69012058 2.13433374]\n",
            "fold3 QWK score: 0.42455 \n",
            "len(trn_idx) : 14152\n",
            "len(val_idx) : 3538\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fold 4\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[581]\ttraining's rmse: 0.938269\tvalid_1's rmse: 1.08673\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fold4 RMSE score: 1.08673 \n",
            "coefficients: [0.51980435 1.6354213  2.15975875]\n",
            "fold4 QWK score: 0.44969 \n",
            "CV RMSE score: 1.08241 \n",
            "coefficients: [0.5289357  1.67460578 2.0973398 ]\n",
            "CV QWK score: 0.44358 \n",
            "=========================================================================================\n",
            "[Run lightgbm] done in 33 s\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tO3KlGxXkAh1",
        "colab_type": "text"
      },
      "source": [
        "### Submit the submission file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIo3VJ6YjHR6",
        "colab_type": "code",
        "outputId": "f279f43f-58d0-4020-b8ca-e25fc688ddbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!kaggle competitions submit -c data-science-bowl-2019 -f /content/drive/My\\ Drive/Kaggle\\ Competition:\\ 2019\\ Data\\ Science\\ Bowl/Outputs/submission.csv -m \"V-01\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "100% 10.8k/10.8k [00:05<00:00, 1.86kB/s]\n",
            "403 - This competition only allows kernel submissions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fadsV3g4kw1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}